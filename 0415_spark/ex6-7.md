```py
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 1.6.0
      /_/

Using Python version 2.7.8 (default, Nov 14 2016 05:07:18)
SparkContext available as sc, HiveContext available as sqlContext.

In [1]: accounts = sc.textFile("hdfs:/loudacre/accounts/part-m-00000")
# 그냥 로드 했을 때 default 2.
In [2]: print accounts.toDebugString()
(2) hdfs:/loudacre/accounts/part-m-00000 MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2 []
 |  hdfs:/loudacre/accounts/part-m-00000 HadoopRDD[0] at textFile at NativeMethodAccessorImpl.java:-2 []
# 로드 할때 파티션 옵션을 3을 준다.
In [3]: part_accounts = sc.textFile("hdfs:/loudacre/accounts/part-m-00000",3)
# 옵션을 주고 확인된 부분은 3으로 변경됨.
In [4]: print part_accounts.toDebugString()
(3) hdfs:/loudacre/accounts/part-m-00000 MapPartitionsRDD[3] at textFile at NativeMethodAccessorImpl.java:-2 []
 |  hdfs:/loudacre/accounts/part-m-00000 HadoopRDD[2] at textFile at NativeMethodAccessorImpl.java:-2 []

In [5]: accountsByID = accounts.map(lambda s: s.split(',')).map(lambda values: (values[0], values[4] + ',' + values[3]))

In [6]: userReqs = sc.textFile("hdfs:/loudacre/weblogs/*2.log")\
   ...:            .map(lambda line: line.split()).map(lambda words: (words[2],1)).reduceByKey(lambda v1, v2: v1+v2)

In [7]: accountHits = accountsByID.join(userReqs).values()
# 결과 출력이 없으면 lazy 하기 때문에 save를 통해 연산처리 시킴.
In [8]: accountHits.saveAsTextFile("hdfs:/loudacre/userreqs")
                                                                                
In [9]: print accountHits.toDebugString()
(20) PythonRDD[20] at RDD at PythonRDD.scala:43 []
 |   MapPartitionsRDD[16] at mapPartitions at PythonRDD.scala:374 []
 |   ShuffledRDD[15] at partitionBy at NativeMethodAccessorImpl.java:-2 []
 +-(20) PairwiseRDD[14] at join at <ipython-input-7-ef6ba18ef7f5>:1 []
    |   PythonRDD[13] at join at <ipython-input-7-ef6ba18ef7f5>:1 []
    |   UnionRDD[12] at union at NativeMethodAccessorImpl.java:-2 []
    |   PythonRDD[10] at RDD at PythonRDD.scala:43 []
    |   hdfs:/loudacre/accounts/part-m-00000 MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2 []
    |   hdfs:/loudacre/accounts/part-m-00000 HadoopRDD[0] at textFile at NativeMethodAccessorImpl.java:-2 []
    |   PythonRDD[11] at RDD at PythonRDD.scala:43 []
    |   MapPartitionsRDD[9] at mapPartitions at PythonRDD.scala:374 []
    |   ShuffledRDD[8] at partitionBy at NativeMethodAccessorImpl.java:-2 []
    +-(18) PairwiseRDD[7] at reduceByKey at <ipython-input-6-debfbf180b07>:1 []
       |   PythonRDD[6] at reduceByKey at <ipython-input-6-debfbf180b07>:1 []
       |   hdfs:/loudacre/weblogs/*2.log MapPartitionsRDD[5] at textFile at NativeMethodAccessorImpl.java:-2 []
       |   hdfs:/loudacre/weblogs/*2.log HadoopRDD[4] at textFile at NativeMethodAccessorImpl.java:-2 []

In [10]: 

In [10]: 

In [10]: accountHits.filter(lambda (firstlast, hitcount) : hitcount > 5 ).count()
Out[10]: 2512

In [11]: accountHits.persist()
Out[11]: PythonRDD[20] at RDD at PythonRDD.scala:43

In [12]: accountHits.filter(lambda (firstlast, hitcount) : hitcount > 5 ).count()
Out[12]: 2512                                                                   

In [13]: accountHits.toDebugString()
Out[13]: '(20) PythonRDD[20] at RDD at PythonRDD.scala:43 [Memory Serialized 1x Replicated]\n |        CachedPartitions: 20; MemorySize: 108.1 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\n |   MapPartitionsRDD[16] at mapPartitions at PythonRDD.scala:374 [Memory Serialized 1x Replicated]\n |   ShuffledRDD[15] at partitionBy at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]\n +-(20) PairwiseRDD[14] at join at <ipython-input-7-ef6ba18ef7f5>:1 [Memory Serialized 1x Replicated]\n    |   PythonRDD[13] at join at <ipython-input-7-ef6ba18ef7f5>:1 [Memory Serialized 1x Replicated]\n    |   UnionRDD[12] at union at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]\n    |   PythonRDD[10] at RDD at PythonRDD.scala:43 [Memory Serialized 1x Replicated]\n    |   hdfs:/loudacre/accounts/part-m-00000 MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]\n    |   hdfs:/loudacre/accounts/part-m-00000 HadoopRDD[0] at textFile at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]\n    |   PythonRDD[11] at RDD at PythonRDD.scala:43 [Memory Serialized 1x Replicated]\n    |   MapPartitionsRDD[9] at mapPartitions at PythonRDD.scala:374 [Memory Serialized 1x Replicated]\n    |   ShuffledRDD[8] at partitionBy at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]\n    +-(18) PairwiseRDD[7] at reduceByKey at <ipython-input-6-debfbf180b07>:1 [Memory Serialized 1x Replicated]\n       |   PythonRDD[6] at reduceByKey at <ipython-input-6-debfbf180b07>:1 [Memory Serialized 1x Replicated]\n       |   hdfs:/loudacre/weblogs/*2.log MapPartitionsRDD[5] at textFile at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]\n       |   hdfs:/loudacre/weblogs/*2.log HadoopRDD[4] at textFile at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]'
# memory serialized 1x replicated 라고 persist 된 정보가 보인다.
In [14]: print accountHits.toDebugString()
(20) PythonRDD[20] at RDD at PythonRDD.scala:43 [Memory Serialized 1x Replicated]
 |        CachedPartitions: 20; MemorySize: 108.1 KB; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B
 |   MapPartitionsRDD[16] at mapPartitions at PythonRDD.scala:374 [Memory Serialized 1x Replicated]
 |   ShuffledRDD[15] at partitionBy at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]
 +-(20) PairwiseRDD[14] at join at <ipython-input-7-ef6ba18ef7f5>:1 [Memory Serialized 1x Replicated]
    |   PythonRDD[13] at join at <ipython-input-7-ef6ba18ef7f5>:1 [Memory Serialized 1x Replicated]
    |   UnionRDD[12] at union at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]
    |   PythonRDD[10] at RDD at PythonRDD.scala:43 [Memory Serialized 1x Replicated]
    |   hdfs:/loudacre/accounts/part-m-00000 MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]
    |   hdfs:/loudacre/accounts/part-m-00000 HadoopRDD[0] at textFile at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]
    |   PythonRDD[11] at RDD at PythonRDD.scala:43 [Memory Serialized 1x Replicated]
    |   MapPartitionsRDD[9] at mapPartitions at PythonRDD.scala:374 [Memory Serialized 1x Replicated]
    |   ShuffledRDD[8] at partitionBy at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]
    +-(18) PairwiseRDD[7] at reduceByKey at <ipython-input-6-debfbf180b07>:1 [Memory Serialized 1x Replicated]
       |   PythonRDD[6] at reduceByKey at <ipython-input-6-debfbf180b07>:1 [Memory Serialized 1x Replicated]
       |   hdfs:/loudacre/weblogs/*2.log MapPartitionsRDD[5] at textFile at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]
       |   hdfs:/loudacre/weblogs/*2.log HadoopRDD[4] at textFile at NativeMethodAccessorImpl.java:-2 [Memory Serialized 1x Replicated]
# persist를 변경하기 위해 unpersist
In [15]: accountHits.unpersist()
Out[15]: PythonRDD[20] at RDD at PythonRDD.scala:43

In [16]: accountHits.persist(StorageLevel.DISK_ONLY)
Out[16]: PythonRDD[20] at RDD at PythonRDD.scala:43
# count를 해야만 퍼시스트가 들어간다.
In [17]: accountHits.filter(lambda (firstlast, hitcount) : hitcount > 5 ).count()
Out[17]: 2512                                                                   

In [18]: 
```